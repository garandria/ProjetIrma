{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TUXML_CSV_FILENAME= \"/mnt/temp_dd/igrida-fs1/macher/config_bdd30To102K.csv\" # \"config_bdd83K.csv\" # 'config_bdd1K.csv' # # \"./config_bdd.csv\" # \n",
    "\n",
    "# sanity check CSV\n",
    "with open(TUXML_CSV_FILENAME, \"r\") as file:\n",
    "    k = file.readline()\n",
    "    t = k.split(\",\")\n",
    "    s = set(t)\n",
    "    assert(len(t) == len(s)) # unique number of options/features/column names\n",
    "\n",
    "# parsing for real with pandas \n",
    "rawtuxdata = pd.read_csv(open(TUXML_CSV_FILENAME, \"r\"))\n",
    "\n",
    "basic_head = [\"cid\", \"time\", \"date\"] # \"compile\"\n",
    "size_methods = [\"vmlinux\", \"GZIP-bzImage\", \"GZIP-vmlinux\", \"GZIP\", \"BZIP2-bzImage\", \n",
    "              \"BZIP2-vmlinux\", \"BZIP2\", \"LZMA-bzImage\", \"LZMA-vmlinux\", \"LZMA\", \"XZ-bzImage\", \"XZ-vmlinux\", \"XZ\", \n",
    "              \"LZO-bzImage\", \"LZO-vmlinux\", \"LZO\", \"LZ4-bzImage\", \"LZ4-vmlinux\", \"LZ4\"]\n",
    "\n",
    "\n",
    "### basic stats about options and remove of unique values \n",
    "## could be improved \n",
    "\n",
    "tri_state_values = ['y', 'n', 'm']\n",
    "\n",
    "ftuniques = []\n",
    "freq_ymn_features = []\n",
    "non_tristate_options = []\n",
    "\n",
    "for col in rawtuxdata:\n",
    "    ft = rawtuxdata[col]    \n",
    "    # eg always \"y\"\n",
    "    if len(ft.unique()) == 1:\n",
    "        ftuniques.append(col)\n",
    "    # only tri-state values (y, n, m) (possible TODO: handle numerical/string options)    \n",
    "    elif all(x in tri_state_values for x in ft.unique()):     #len(ft.unique()) == 3: \n",
    "        freq = ft.value_counts(normalize=True)\n",
    "        freqy = 0\n",
    "        freqn = 0\n",
    "        freqm = 0\n",
    "        if ('y' in freq.index):\n",
    "            freqy = freq['y']\n",
    "        if ('n' in freq.index):\n",
    "            freqn = freq['n']\n",
    "        if ('m' in freq.index):\n",
    "            freqm = freq['m']\n",
    "        freq_ymn_features.append((col, freqy, freqm, freqn))\n",
    "    else:\n",
    "        if not (col in size_methods): \n",
    "            non_tristate_options.append(col)\n",
    "        \n",
    "\n",
    "### TODO: we want to keep all quantitative values!\n",
    "# non_tristate_options.remove('LZO') # ('vmlinux')\n",
    "\n",
    "# we want to keep measurements (that are not tristate ;)) \n",
    "# non_tristate_options = list(set(non_tristate_options) - set(size_methods))\n",
    "\n",
    "#### print options with unique values\n",
    "# options with only one value eg always \"y\"\n",
    "#i = 0\n",
    "#for ft in ftuniques:\n",
    "#    print(ft + \" (\" + str(i) + \")\")\n",
    "#    i = i + 1\n",
    "\n",
    "print(\"Original size (#configs/#options) of the dataset \" + str(rawtuxdata.shape))\n",
    "print (\"Number of options with only one value (eg always y): \" + str(pd.DataFrame(ftuniques).shape))\n",
    "\n",
    "# maybe we can drop options with only one unique value (no interest for machine learning)\n",
    "# TODO: maybe we can rely on more traditional feature reduction techniques\n",
    "# TODO: need to think about *when* to apply the removal \n",
    "rawtuxdata.drop(columns=ftuniques,inplace=True) \n",
    "## non_tristate_options include basic stuff like date, time, cid but also string/numerical options\n",
    "print (\"Non tri-state value options (eg string or integer or hybrid values): \" \n",
    "       + str(pd.DataFrame(non_tristate_options).shape) + \" \") \n",
    "#      + str(pd.DataFrame(non_tristate_options)))\n",
    "\n",
    "\n",
    "print (\"Predictor variables: \" + str(rawtuxdata.drop(columns=non_tristate_options).columns.size))\n",
    "# frequency of y, m, and n values \n",
    "#plt.figure()\n",
    "#pd.DataFrame(freq_ymn_features, columns=[\"feature\", \"freqy\", \"freqm\", \"freqn\"]).plot(kind='hist', alpha=0.8) #plot()\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'X86_64' in ftuniques, 'DEBUG_INFO' in ftuniques, 'GCOV_PROFILE_ALL' in ftuniques, 'KASAN' in ftuniques, 'UBSAN_SANITIZE_ALL' in ftuniques, 'RELOCATABLE' in ftuniques, 'XFS_DEBUG' in ftuniques, 'AIC7XXX_BUILD_FIRMWARE' in ftuniques, 'AIC79XX_BUILD_FIRMWARE' in ftuniques, 'WANXL_BUILD_FIRMWARE' in ftuniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tinyconfig \n",
    "rawtuxdata['SLOB'].value_counts(), rawtuxdata['CC_OPTIMIZE_FOR_SIZE'].value_counts(), rawtuxdata['OPTIMIZE_INLINING'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'RELOCATABLE' in rawtuxdata.columns:\n",
    "    print(rawtuxdata.query(\"RELOCATABLE == 'y'\")[['cid', 'RELOCATABLE']], rawtuxdata.query(\"RELOCATABLE == 'y'\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data exploration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUGS EXPLORATION\n",
    "def bug_exploration():\n",
    "    rawtuxdata.query(\"AIC7XXX_BUILD_FIRMWARE == 'y'\")[['cid', 'vmlinux']]\n",
    "    rawtuxdata.query(\"AIC79XX_BUILD_FIRMWARE == 'y'\")[['cid', 'vmlinux']]\n",
    "    rawtuxdata.query(\"WANXL_BUILD_FIRMWARE == 'y'\")[['cid', 'vmlinux']]\n",
    "    rawtuxdata.query(\"GENERIC_ALLOCATOR == 'n' & DRM_VBOXVIDEO == 'y'\")[['cid', 'vmlinux']]\n",
    "    rawtuxdata.query(\"GENERIC_ALLOCATOR == 'y' & DRM_VBOXVIDEO == 'y'\")[['cid', 'vmlinux']]\n",
    "    rawtuxdata.query(\"GENERIC_ALLOCATOR == 'n' & DRM_VBOXVIDEO == 'm'\")[['cid', 'vmlinux']]\n",
    "    return rawtuxdata.query(\"DRM_VBOXVIDEO == 'y'\")[['cid', 'vmlinux']]\n",
    "\n",
    "#bug_exploration()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rawtuxdata[rawtuxdata['X86_64'] == 'n']\n",
    "#rawtuxdata.query(\"X86_64 == 'n'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rawtuxdata[(rawtuxdata['DEBUG_INFO'] == 'n') & (rawtuxdata['GCOV_PROFILE_ALL'] == 'n') & (rawtuxdata['KASAN'] == 'n') & (rawtuxdata['MODULES'] == 'y')]\n",
    "# rawtuxdata.query(\"(DEBUG_INFO == 'n') & (GCOV_PROFILE_ALL == 'n') & (KASAN == 'n') & (MODULES == 'y')\")\n",
    "#rawtuxdata.query(\"(DEBUG_INFO == 'n') & (GCOV_PROFILE_ALL == 'n') & (KASAN == 'n')\").shape, rawtuxdata.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rawtuxdata[rawtuxdata['vmlinux'] == 1168072][['cid', 'CC_OPTIMIZE_FOR_SIZE', 'DEBUG_INFO_DWARF4', 'KASAN', 'UBSAN_ALIGNMENT', 'X86_NEED_RELOCS', 'RANDOMIZE_BASE', 'GCOV_PROFILE_ALL', 'UBSAN_SANITIZE_ALL', 'DEBUG_INFO', 'MODULES', 'DEBUG_INFO_REDUCED', 'DEBUG_INFO_SPLIT']]\n",
    "tiny_data = rawtuxdata.query(\"vmlinux == 1168072\") #tiny config for X86_32\n",
    "#if (len(tiny_data) > 0):\n",
    "#    print(tiny_data[['cid', 'CC_OPTIMIZE_FOR_SIZE', 'DEBUG_INFO_DWARF4', 'KASAN', 'UBSAN_ALIGNMENT', 'X86_NEED_RELOCS', 'RANDOMIZE_BASE', 'GCOV_PROFILE_ALL', 'UBSAN_SANITIZE_ALL', 'DEBUG_INFO', 'MODULES', 'DEBUG_INFO_REDUCED', 'DEBUG_INFO_SPLIT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rawtuxdata[rawtuxdata['vmlinux'] == -1]\n",
    "rawtuxdata.query(\"vmlinux == -1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rawtuxdata[rawtuxdata['vmlinux'] == 1168072]['MODULES']\n",
    "rawtuxdata.query(\"vmlinux == 1168072\")['MODULES'] #tiny config for X86_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playing a bit with the data \n",
    "rawtuxdata.dtypes\n",
    "# 'DEBUG_INFOO' in list(pd.DataFrame(non_tristate_options)[0]) # \n",
    "# tuxdata['DEBUG_INFO'].unique()\n",
    "#tuxdata['OUTPUT_FORMAT'].dtypes\n",
    "#tuxdata['DEFAULT_HOSTNAME'].unique()\n",
    "\n",
    "#rawtuxdata[:5]\n",
    "rawtuxdata[:20]['vmlinux']\n",
    "#tuxdata[:5]['CONFIG_DEBUG_INFO']\n",
    "#tuxdata['ARCH_HAS_SG_CHAIN'].unique()\n",
    "#tuxdata['ARCH_HAS_SG_CHAIN'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtuxdata.shape, rawtuxdata.query(\"vmlinux != -1\").shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"some configurations may have X86_32 (coz we have tested/tried some options and there are in the database)\")\n",
    "# we only keep X86_64 configurations\n",
    "#rawtuxdata = rawtuxdata[rawtuxdata['X86_64'] == 'y'] ### TODO: I've impression it's not the most effective way (wrt memory) to filter \n",
    "if 'X86_64' in rawtuxdata.columns:\n",
    "    print(rawtuxdata['X86_64'].describe())\n",
    "    rawtuxdata.query(\"X86_64 == 'y'\", inplace=True)\n",
    "rawtuxdata.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "\n",
    "\n",
    "LEARN_COMPILATION_SUCCESS = False # costly in time and space \n",
    "compilation_status_column_name = 'compile_success'\n",
    "\n",
    "def encode_data_compilation(rawtuxdata):\n",
    "    lae = LabelEncoder()\n",
    "    # we save quantitative values we want (here vmlinux, TODO: generalize)\n",
    "    # the key idea is that the labelling encoder should not be applied to this kind of values (only to predictor variables!)\n",
    "    # vml = rawtuxdata['LZO'] # rawtuxdata['vmlinux'] \n",
    "    o_sizes = rawtuxdata[size_methods]\n",
    "\n",
    "    # we remove non tri state options, but TODO there are perhaps some interesting options (numerical or string) here\n",
    "    #tuxdata = rawtuxdata.drop(columns=non_tristate_options).drop(columns=['vmlinux']).apply(le.fit_transform)\n",
    "    tuxdata_for_compilation = rawtuxdata.drop(columns=non_tristate_options).drop(columns=size_methods).apply(lae.fit_transform)\n",
    "\n",
    "    #tuxdata['vmlinux'] = vml \n",
    "    tuxdata_for_compilation[size_methods] = o_sizes\n",
    "    # we can ue vmlinux since it has been restored thanks to previous line\n",
    "    tuxdata_for_compilation[compilation_status_column_name] = tuxdata_for_compilation['vmlinux'] != -1\n",
    "    return tuxdata_for_compilation\n",
    "\n",
    "def learn_compilation_success(tuxdata_for_compilation):\n",
    "    TESTING_SIZE=0.3 \n",
    "    X_train, X_test, y_train, y_test = train_test_split(tuxdata_for_compilation.drop(columns=size_methods).drop(columns=compilation_status_column_name), tuxdata_for_compilation[compilation_status_column_name], test_size=TESTING_SIZE, random_state=0)  \n",
    "    clf = tree.DecisionTreeClassifier() #GradientBoostingClassifier(n_estimators=100) #RandomForestRegressor(n_estimators=100) #   #GradientBoostingRegressor(n_estimators=100)  \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    importances = clf.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]    \n",
    "\n",
    "    TOP_FT_IMPORTANCE=20\n",
    "    print(\"Feature ranking: \" + \"top (\" + str(TOP_FT_IMPORTANCE) + \")\")\n",
    "    for f in range(TOP_FT_IMPORTANCE): # len(indices)\n",
    "        print(\"%d. feature %s %d (%f)\" % (f + 1, tuxdata_for_compilation.columns[indices[f]], indices[f], importances[indices[f]]))\n",
    "   \n",
    "    \n",
    "    dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                         feature_names=tuxdata_for_compilation.drop(columns=size_methods).drop(columns=compilation_status_column_name).columns,  \n",
    "                         filled=True, rounded=True,\n",
    "                         special_characters=True)  \n",
    "    graph = graphviz.Source(dot_data)  \n",
    "    graph.render(\"TUXML compilation sucess\")\n",
    "    \n",
    "    acc = accuracy_score (y_test, y_pred)\n",
    "    prec = precision_score (y_test, y_pred)\n",
    "    reca = recall_score (y_test, y_pred)\n",
    "    f1 = f1_score (y_test, y_pred)\n",
    "    print(\"Accuracy score: %.2f\" % (acc))\n",
    "    print(\"Precision score: %.2f\" % (prec))\n",
    "    print(\"Recall score: %.2f\" % (reca))\n",
    "    print(\"F1 score: %.2f\" % (f1))\n",
    "\n",
    "if (LEARN_COMPILATION_SUCCESS):\n",
    "    tuxdata_for_compilation = encode_data_compilation(rawtuxdata)\n",
    "    tuxdata_for_compilation [compilation_status_column_name].describe()\n",
    "    learn_compilation_success(tuxdata_for_compilation)\n",
    "    del tuxdata_for_compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rawtuxdata.query(\"vmlinux == -1\")[['cid', 'AIC7XXX_BUILD_FIRMWARE', 'AIC79XX_BUILD_FIRMWARE', 'IPVTAP', 'WANXL_BUILD_FIRMWARE', 'TCIC']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aka MAPE\n",
    "def mean_relative_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove entries with same configurations\n",
    "print(str(len(rawtuxdata)) + \" before the removal of some entries (those with same configurations)\")\n",
    "# tuxdata.drop_duplicates(subset=tuxdata.columns.difference(['vmlinux']), inplace=True)\n",
    "rawtuxdata.drop_duplicates(subset=rawtuxdata.columns.difference(size_methods).difference(basic_head), inplace=True)\n",
    "print(str(len(rawtuxdata)) + \" after the removal of some entries (those with same configurations)\")\n",
    "\n",
    "#n_failures = len(tuxdata[~np.isnan(tuxdata['vmlinux'])])\n",
    "#n_failures = len(rawtuxdata.query(\"vmlinux != -1\")) #len(tuxdata[np.isnan(tuxdata['vmlinux'])])\n",
    "#print(str(n_failures) + \" non-failures out of \" + str(len(rawtuxdata)))\n",
    "\n",
    "#tuxdata = tuxdata[~np.isnan(tuxdata['vmlinux'])]\n",
    "#rawtuxdata = rawtuxdata[rawtuxdata['vmlinux'] != -1] #tuxdata[~np.isnan(tuxdata['vmlinux'])]\n",
    "rawtuxdata.query(\"(vmlinux != -1) & (vmlinux != 0)\", inplace=True)\n",
    "print(str(len(rawtuxdata)) + \" after the removal of configurations that do NOT compile\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtuxdata.query(\"vmlinux == 1168072\") # tinyconfig with X86_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtuxdata.query(\"vmlinux == 7317008\") # tiny config for X86_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "pd.DataFrame(rawtuxdata['vmlinux']).plot.box()\n",
    "plt.show(block=False)\n",
    "\n",
    "plt.figure()\n",
    "pd.DataFrame(rawtuxdata['LZO']).plot.box()\n",
    "plt.show(block=False)\n",
    "\n",
    "plt.figure()\n",
    "pd.DataFrame(rawtuxdata['BZIP2']).plot.box()\n",
    "plt.show(block=False)\n",
    "\n",
    "\n",
    "rawtuxdata['vmlinux'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtuxdata['vmlinux'].sort_values()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "def color_negative_positive(val, pcolor=\"green\", ncolor=\"red\"):\n",
    "    \"\"\"\n",
    "    Takes a scalar and returns a string with\n",
    "    the css property `'color: red'` for negative\n",
    "    strings, black otherwise.\n",
    "    \"\"\"\n",
    "    color = pcolor if val > 0 else ncolor \n",
    "    if val == 0:\n",
    "        color = 'black' \n",
    "    return 'color: %s' % color\n",
    "\n",
    "compress_methods = [\"GZIP\", \"BZIP2\", \"LZMA\", \"XZ\", \"LZO\", \"LZ4\"]\n",
    "def compareCompress(size_measure_of_interest): #\"\" # \"-vmlinux\" #\"-bzImage\" # prefix\n",
    "    rCompressDiff = pd.DataFrame(index=list(map(lambda c: c + \"o\", compress_methods)) , columns=compress_methods) \n",
    "    for compress_method in compress_methods:\n",
    "        for compress_method2 in compress_methods:\n",
    "            rCompressDiff.loc[compress_method + \"o\"][compress_method2] = (np.mean(rawtuxdata[compress_method + size_measure_of_interest] / rawtuxdata[compress_method2 + size_measure_of_interest]) * 100) - 100\n",
    "    return rCompressDiff\n",
    "\n",
    "#cmy = sns.light_palette(\"red\", as_cmap=True)\n",
    "compareCompress(\"\").style.set_caption('Difference (average in percentage) per compression methods').applymap(color_negative_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compareCompress(\"-bzImage\").style.set_caption('Difference (average in percentage) per compression methods, bzImage').applymap(color_negative_positive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compareCompress(\"-vmlinux\").style.set_caption('Difference (average in percentage) per compression methods, vmlinux').applymap(color_negative_positive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "pd.DataFrame.corr(rawtuxdata[size_methods]).style.set_caption('Correlations between size measures').background_gradient(cmap=cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from category_encoders import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "## class to integer encoding (y, n, m)\n",
    "\n",
    "## note: we also remove non-tristate-options\n",
    "# \"in place\" is to avoid memory burden (having two dfs in memory)\n",
    "\n",
    "# encode labels with value between 0 and n_classes-1.\n",
    "le = LabelEncoder()\n",
    "# 2/3. FIT AND TRANSFORM\n",
    "vml = rawtuxdata[size_methods]\n",
    "\n",
    "# we remove non tri state options, but TODO there are perhaps some interesting options (numerical or string) here\n",
    "#tuxdata = rawtuxdata.drop(columns=non_tristate_options).drop(columns=['vmlinux']).apply(le.fit_transform)\n",
    "rawtuxdata = rawtuxdata.drop(columns=non_tristate_options).drop(columns=size_methods).apply(le.fit_transform)\n",
    "\n",
    "#tuxdata['vmlinux'] = vml \n",
    "rawtuxdata[size_methods] = vml\n",
    " \n",
    "rawtuxdata.shape, rawtuxdata.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### takes a while\n",
    "# One-Hot-Encoding \n",
    "#from sklearn.preprocessing import *\n",
    "\n",
    "#enc = OneHotEncoder()\n",
    "#o_sizes = rawtuxdata[size_methods]\n",
    "#oh_tuxdata = enc.fit_transform(rawtuxdata)\n",
    "#oh_tuxdata.shape, o_sizes.shape\n",
    "# rawtuxdata.drop(columns=non_tristate_options).drop(columns=size_methods).apply(enc.fit_transform)\n",
    "#oh_tuxdata[size_methods] = o_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUMMY (with Pandas)\n",
    "\n",
    "#o_sizes = tuxdata[size_methods]\n",
    "#tuxdata_dummy = pd.get_dummies(rawtuxdata.drop(columns=size_methods), columns=rawtuxdata.drop(columns=size_methods).columns)\n",
    "#tuxdata_dummy[size_methods] = o_sizes\n",
    "#tuxdata_dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data exploration (again)\n",
    "#print(rawtuxdata['UBSAN_SANITIZE_ALL'].value_counts(), rawtuxdata['COMPILE_TEST'].value_counts(), rawtuxdata['NOHIGHMEM'].value_counts(), rawtuxdata['OPTIMIZE_INLINING'].value_counts(), rawtuxdata['SLOB'].value_counts(), rawtuxdata['CC_OPTIMIZE_FOR_SIZE'].value_counts(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class LearningStrategy(Enum):\n",
    "    LINEAR = 1\n",
    "    AUTOML = 2\n",
    "    ML = 3\n",
    "    DT = 4 # decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# https://ramhiser.com/post/2018-03-25-feature-selection-with-scikit-learn-pipeline/\n",
    "class PipelineRFE(Pipeline):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        super(PipelineRFE, self).fit(X, y, **fit_params)\n",
    "        self.feature_importances_ = self.steps[-1][-1].feature_importances_\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_ENCODED_VALUE = le.transform(['n'])[0] \n",
    "\n",
    "def mkNoOption(option_name):\n",
    "    return \"(\" + option_name + \" == \" + str(NO_ENCODED_VALUE) + \")\"\n",
    "\n",
    "def mkNoOptions(l_options):\n",
    "    r = []\n",
    "    for option_name in l_options:\n",
    "        r.append(mkNoOption(option_name))\n",
    "        \n",
    "    return ' & '.join(r)\n",
    "\n",
    "mkNoOptions(['DEBUG_INFO', 'GCOV_PROFILE_ALL', 'KASAN', 'UBSAN_SANITIZE_ALL', 'RELOCATABLE', 'XFS_DEBUG'])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from tpot import TPOTRegressor\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prefilter_data(tuxdata):    \n",
    "    # return rawtuxdata\n",
    "    #return rawtuxdata.query(mkNoOption(\"DEBUG_INFO\"))\n",
    "    #return rawtuxdata.query(mkNoOption(\"DEBUG_INFO\") + \" & \" + mkNoOption(\"GCOV_PROFILE_ALL\") + \" & \" + mkNoOption(\"KASAN\") + \" & \" + mkNoOption(\"UBSAN_SANITIZE_ALL\") + \" & \" + mkNoOption(\"RELOCATABLE\") + \" & \" + mkNoOption(\"XFS_DEBUG\"))\n",
    "    return rawtuxdata.query(mkNoOptions(['DEBUG_INFO', 'GCOV_PROFILE_ALL', 'KASAN', 'UBSAN_SANITIZE_ALL', 'RELOCATABLE', 'XFS_DEBUG']))  \n",
    "                \n",
    "\n",
    "def regLearning(tuxdata, kindOfLearning=LearningStrategy.ML):\n",
    " \n",
    "    TESTING_SIZE=0.1 # 0.9 means 10% for training, 90% for testing\n",
    "    size_of_interest = \"vmlinux\" # could be LZO, BZIP, etc. \n",
    "    PRINT_FEATURE_IMPORTANCES = True\n",
    "   \n",
    "       \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(tuxdata[(tuxdata['DEBUG_INFO'] == le.transform(['n'])[0])].drop(columns=size_methods), tuxdata[(tuxdata['DEBUG_INFO'] == le.transform(['n'])[0])][size_of_interest], test_size=TESTING_SIZE, random_state=0)  \n",
    "    print (\"Warning: prefiltering on DEBUG_INFO=n GCOV_PROFILE_ALL=n KASAN=n ....\")   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(prefilter_data(tuxdata).drop(columns=size_methods), prefilter_data(tuxdata)[size_of_interest], test_size=TESTING_SIZE, random_state=0)  \n",
    "  \n",
    "    # multi output\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(tuxdata.drop(columns=size_methods), tuxdata[size_methods], test_size=TESTING_SIZE, random_state=0)  \n",
    "\n",
    "    # train_test_split(tuxdata.drop(columns=['vmlinux']), tuxdata['vmlinux'], test_size=TESTING_SIZE, random_state=0)  \n",
    "\n",
    "    #clf = RandomForestRegressor(n_estimators=100) \n",
    "\n",
    "    if kindOfLearning == LearningStrategy.LINEAR:\n",
    "        regr =  linear_model.Lasso() # svm.SVC(kernel='linear') # linear_model.Ridge(alpha=.1) #  # linear_model.Lasso() # linear_model.SGDRegressor() #LinearRegression() # SGDRegressor or linear_model.Lasso()\n",
    "        regr.fit(X_train, y_train)\n",
    "        y_pred = regr.predict(X_test)\n",
    "\n",
    "    elif kindOfLearning == LearningStrategy.AUTOML:\n",
    "\n",
    "\n",
    "        tpot_config = {\n",
    "\n",
    "            'sklearn.linear_model.ElasticNetCV': {\n",
    "                'l1_ratio': np.arange(0.0, 1.01, 0.05),\n",
    "                'tol': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "            },\n",
    "\n",
    "            'sklearn.ensemble.ExtraTreesRegressor': {\n",
    "                'n_estimators': [100],\n",
    "                'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "                'min_samples_split': range(2, 21),\n",
    "                'min_samples_leaf': range(1, 21),\n",
    "                'bootstrap': [True, False]\n",
    "            },\n",
    "\n",
    "            'sklearn.ensemble.GradientBoostingRegressor': {\n",
    "                'n_estimators': [100],\n",
    "                'loss': [\"ls\", \"lad\", \"huber\", \"quantile\"],\n",
    "                'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "                'max_depth': range(1, 11),\n",
    "                'min_samples_split': range(2, 21),\n",
    "                'min_samples_leaf': range(1, 21),\n",
    "                'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "                'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "                'alpha': [0.75, 0.8, 0.85, 0.9, 0.95, 0.99]\n",
    "            },\n",
    "\n",
    "            'sklearn.ensemble.AdaBoostRegressor': {\n",
    "                'n_estimators': [100],\n",
    "                'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "                'loss': [\"linear\", \"square\", \"exponential\"],\n",
    "                'max_depth': range(1, 11)\n",
    "            },\n",
    "\n",
    "            'sklearn.tree.DecisionTreeRegressor': {\n",
    "                'max_depth': range(1, 11),\n",
    "                'min_samples_split': range(2, 21),\n",
    "                'min_samples_leaf': range(1, 21)\n",
    "            },\n",
    "\n",
    "            'sklearn.neighbors.KNeighborsRegressor': {\n",
    "                'n_neighbors': range(1, 101),\n",
    "                'weights': [\"uniform\", \"distance\"],\n",
    "                'p': [1, 2]\n",
    "            },\n",
    "\n",
    "            'sklearn.linear_model.LassoLarsCV': {\n",
    "                'normalize': [True, False]\n",
    "            },\n",
    "\n",
    "            'sklearn.svm.LinearSVR': {\n",
    "                'loss': [\"epsilon_insensitive\", \"squared_epsilon_insensitive\"],\n",
    "                'dual': [True, False],\n",
    "                'tol': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "                'C': [1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1., 5., 10., 15., 20., 25.],\n",
    "                'epsilon': [1e-4, 1e-3, 1e-2, 1e-1, 1.]\n",
    "            },\n",
    "\n",
    "            'sklearn.ensemble.RandomForestRegressor': {\n",
    "                'n_estimators': [100],\n",
    "                'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "                'min_samples_split': range(2, 21),\n",
    "                'min_samples_leaf': range(1, 21),\n",
    "                'bootstrap': [True, False]\n",
    "            },\n",
    "\n",
    "            'sklearn.linear_model.RidgeCV': {\n",
    "            },\n",
    "\n",
    "            'xgboost.XGBRegressor': {\n",
    "                'n_estimators': [100],\n",
    "                'max_depth': range(1, 11),\n",
    "                'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "                'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "                'min_child_weight': range(1, 21),\n",
    "                'nthread': [1]\n",
    "            }     \n",
    "        }\n",
    "\n",
    "        tpot = TPOTRegressor(generations=5, population_size=50, verbosity=3, config_dict=tpot_config, scoring='neg_mean_absolute_error')\n",
    "        tpot.fit(X_train, y_train)\n",
    "        y_pred = tpot.predict(X_test)\n",
    "        print(tpot.score(X_test, y_test))\n",
    "        print(tpot.evaluated_individuals_)\n",
    "        tpot.export('tpot_boston_pipeline.py')\n",
    "        \n",
    "    elif kindOfLearning == LearningStrategy.DT:\n",
    "        clf = tree.DecisionTreeRegressor() #GradientBoostingClassifier(n_estimators=100) #RandomForestRegressor(n_estimators=100) #   #GradientBoostingRegressor(n_estimators=100)  \n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                         feature_names=tuxdata.drop(columns=size_methods).columns,  \n",
    "                         filled=True, rounded=True,\n",
    "                         special_characters=True)  \n",
    "        graph = graphviz.Source(dot_data)  \n",
    "        graph.render(\"TUXML-DT-\" + size_of_interest)\n",
    "\n",
    "    else:\n",
    "        assert (kindOfLearning == LearningStrategy.ML)\n",
    "        clf = GradientBoostingRegressor(n_estimators=100) # RandomForestRegressor(n_estimators=100) # #GradientBoostingRegressor(n_estimators=100) # KNeighborsRegressor() #RandomForestRegressor(n_estimators=100) # linear_model.SGDRegressor(alpha=0.15, max_iter=200)\n",
    "        # #LassoLarsCV() # MLPRegressor() # GradientBoostingRegressor(n_estimators=100) # ExtraTreesRegressor(n_estimators=100) #RandomForestRegressor(n_estimators=100) # ExtraTreesRegressor(n_estimators=100) #  #   GradientBoostingRegressor(n_estimators=100) # \n",
    "        # \n",
    "        #estimator = RandomForestRegressor(n_estimators=100) # RidgeCV(alphas=[1000.0]) # LassoCV(tol = 0.001) #   #  # RandomForestRegressor(n_estimators=100) #LassoCV() #RidgeCV(alphas=[2000.0]) # LassoCV()\n",
    "        #clf = PipelineRFE([ # Pipeline([\n",
    "        #  ('feature_selection', SelectFromModel(estimator)), # tol = 0.001\n",
    "        #  ('regression', GradientBoostingRegressor(n_estimators=100))\n",
    "        #])\n",
    "        #clf = PipelineRFE([\n",
    "          #('reduce_dim', PCA()),\n",
    "        #  ('feature_selection', SelectFromModel(estimator)), # tol = 0.001\n",
    "        #  ('regression', GradientBoostingRegressor(n_estimators=100))\n",
    "        #])\n",
    "        #clf = make_pipeline(\n",
    "        #    StackingEstimator(estimator=LassoLarsCV(normalize=False)),\n",
    "        #    StackingEstimator(estimator=RandomForestRegressor(bootstrap=True, max_features=0.6500000000000001, min_samples_leaf=10, min_samples_split=2, n_estimators=100)),\n",
    "        #    KNeighborsRegressor(n_neighbors=82, p=2, weights=\"distance\")\n",
    "        #)\n",
    "\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        if PRINT_FEATURE_IMPORTANCES:\n",
    "            importances = clf.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]    \n",
    "\n",
    "            TOP_FT_IMPORTANCE=100\n",
    "            print(\"Feature ranking: \" + \"top (\" + str(TOP_FT_IMPORTANCE) + \")\")\n",
    "            for f in range(TOP_FT_IMPORTANCE): # len(indices)\n",
    "                print(\"%d. feature %s %d (%f)\" % (f + 1, tuxdata.columns[indices[f]], indices[f], importances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    #plt.figure()\n",
    "    #plt.title(\"Feature importances for size of vmlinux\")\n",
    "    #plt.bar(range(tuxdata.shape[1]), importances[indices], color=\"r\", align=\"center\")\n",
    "    #plt.xticks(range(tuxdata.shape[1]), indices)\n",
    "    #plt.xlim([-1, tuxdata.shape[1]])\n",
    "    #plt.show()\n",
    "    mae = mean_absolute_error (y_test, y_pred)# , multioutput='raw_values')\n",
    "    mse = mean_squared_error (y_test, y_pred) #, multioutput='raw_values') \n",
    "    r2 = r2_score (y_test, y_pred) #, multioutput='raw_values') \n",
    "    mre = mean_relative_error (y_test, y_pred)\n",
    "\n",
    "    ONE_MEGABYTE = 1048576\n",
    "\n",
    "    print(\"Prediction score (MAE): %.2f\" % (mae / ONE_MEGABYTE))\n",
    "    print(\"Prediction score (MSE): %.2f\" % (mse / ONE_MEGABYTE))\n",
    "    print(\"Prediction score (R2): %.2f\" % (r2))\n",
    "    print(\"Prediction score (MRE): %.2f\" % (mre))\n",
    "    return y_pred, y_test\n",
    "    \n",
    "pr, re = regLearning(rawtuxdata, LearningStrategy.DT)\n",
    "#regLearning(tuxdata_dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re[56589]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import ExtraTreesClassifier\n",
    "#from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#model = SelectFromModel(clf, prefit=True)\n",
    "#tuxdata_reduced = model.transform(tuxdata.drop(columns=size_methods))\n",
    "#tuxdata_reduced.shape, tuxdata.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "\n",
    "\n",
    "#alphas=[0.1, 1.0, 10.0, 100.0, 500.0, 750.0, 1000.0, 2000.0, 2500.0, 3000.0, 5000.0, 10000.0]\n",
    "#selector = RidgeCV(alphas=[0.1, 1.0, 10.0, 100.0, 500.0, 750.0, 1000.0, 2000.0, 2500.0, 3000.0, 5000.0, 10000.0]) # LassoCV(tol = 0.001) # RidgeCV(alphas=[2000.0])  # \n",
    "#lass = selector #SelectFromModel(selector) #  RFECV(estimator=selector, step=1, scoring='neg_mean_squared_error') # \n",
    "#lass = RFE(estimator=selector, step=1)\n",
    "#lass.fit(X_train, y_train)\n",
    "#tuxdata_reduced_lass = lass.transform(tuxdata.drop(columns=size_methods))\n",
    "#tuxdata_reduced_lass.shape, tuxdata.shape  \n",
    "#lass.alpha_ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import PCA\n",
    "\n",
    "#pca = PCA(n_components=100)\n",
    "#pca.fit(X_train, y_train)\n",
    "\n",
    "#tuxdata_reduced_pca = pca.transform(tuxdata.drop(columns=size_methods))\n",
    "#tuxdata_reduced_pca.shape, tuxdata.shape  \n",
    "\n",
    "#pca.components_.shape\n",
    "\n",
    "#plt.matshow(pca.components_, cmap='viridis')\n",
    "#plt.yticks([0, 1], [\"First component\", \"Second component\"])\n",
    "#plt.colorbar()\n",
    "#plt.xticks(range(len(X_train.columns)),\n",
    "#           X_train.columns, rotation=60, ha='left')\n",
    "#plt.xlabel(\"Feature\")\n",
    "#plt.ylabel(\"Principal components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_vals = ['y', 'n'] \n",
    "tri_state_values = ['y', 'n', 'm']\n",
    "all(x in tri_state_values for x in ft_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tux1 in tuxdata:\n",
    "#    ft1 = tuxdata[tux1]\n",
    "#    for tux2 in tuxdata:\n",
    "#        if (tux1 != tux2):\n",
    "#            if (ft1.all() == tuxdata[tux2].all()):\n",
    "#                print (\"feature \" + str(tux1) + \" always have the same values than \" + str(tux2))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provisoire = pd.read_csv(open('provisoire.csv', \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provisoire[['cid','CC_OPTIMIZE_FOR_SIZE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rawtuxdata.columns[6015] #Columns (1150,6015,6026,7676,7726)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size_methods = [\"vmlinux\", \"GZIP-bzImage\", \"GZIP-vmlinux\", \"GZIP\", \"BZIP2-bzImage\", \n",
    "#              \"BZIP2-vmlinux\", \"BZIP2\", \"LZMA-bzImage\", \"LZMA-vmlinux\", \"LZMA\", \"XZ-bzImage\", \"XZ-vmlinux\", \"XZ\", \n",
    "#              \"LZO-bzImage\", \"LZO-vmlinux\", \"LZO\", \"LZ4-bzImage\", \"LZ4-vmlinux\", \"LZ4\"]\n",
    "#size_methods_without_soi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import h2o\n",
    "#from h2o.automl import H2OAutoML\n",
    "#h2o.init()\n",
    "#df = h2o.import_file(TUXML_CSV_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splits = df.split_frame(ratios = [0.8], seed = 1)\n",
    "#train = splits[0]\n",
    "#test = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = size_of_interest\n",
    "#aml = H2OAutoML(max_runtime_secs = 36000, seed = 1, project_name = \"tuxlearning\")\n",
    "#aml.train(y = y, training_frame = train, leaderboard_frame = test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aml.leaderboard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = aml.predict(test)\n",
    "#pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perf = aml.leader.model_performance(test)\n",
    "#perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h2o.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import category_encoders as ce\n",
    "\n",
    "#colmatters = list(tuxdata.columns)\n",
    "#for s in size_methods:\n",
    "#    colmatters.remove(s)\n",
    "    \n",
    "# colmatters.remove(size_methods)\n",
    "#encoder = ce.OneHotEncoder(cols=colmatters) #cols=tuxdata.drop(columns=size_methods).columns\n",
    "\n",
    "#o_sizes = tuxdata[size_methods]\n",
    "#encoder.fit(tuxdata.drop(columns=size_methods))\n",
    "#tuxdata_dummy2 = encoder.transform(tuxdata.drop(columns=size_methods))\n",
    "#tuxdata_dummy2[size_methods] = o_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rawtuxdata[rawtuxdata['vmlinux'] == 1168072]#['MODULES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuxdata_dummy2.shape, tuxdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rawtuxdata[(rawtuxdata['MODULES'] == 'y')]['vmlinux'].describe(), rawtuxdata[(rawtuxdata['MODULES'] == 'n')]['vmlinux'].describe()\n",
    "#rawtuxdata[(rawtuxdata['UBSAN_SANITIZE_ALL'] == 'y')]\n",
    "# [['cid', 'CC_OPTIMIZE_FOR_SIZE', 'DEBUG_INFO_DWARF4', 'KASAN', 'UBSAN_ALIGNMENT', 'X86_NEED_RELOCS', 'RANDOMIZE_BASE', 'GCOV_PROFILE_ALL', 'UBSAN_SANITIZE_ALL', 'DEBUG_INFO', 'MODULES', 'DEBUG_INFO_REDUCED', 'DEBUG_INFO_SPLIT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtuxdata.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
