{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TUXML_CSV_FILENAME=\"./config_bdd.csv\"\n",
    "\n",
    "# sanity check CSV\n",
    "with open(TUXML_CSV_FILENAME, \"r\") as file:\n",
    "    k = file.readline()\n",
    "    t = k.split(\",\")\n",
    "    s = set(t)\n",
    "    assert(len(t) == len(s)) # unique number of options/features/column names\n",
    "\n",
    "# parsing for real with pandas \n",
    "rawtuxdata = pd.read_csv(open(TUXML_CSV_FILENAME, \"r\"))\n",
    "\n",
    "basic_head = [\"cid\", \"time\"] # \"compile\"\n",
    "size_methods = [\"vmlinux\", \"GZIP-bzImage\", \"GZIP-vmlinux\", \"GZIP\", \"BZIP2-bzImage\", \n",
    "              \"BZIP2-vmlinux\", \"BZIP2\", \"LZMA-bzImage\", \"LZMA-vmlinux\", \"LZMA\", \"XZ-bzImage\", \"XZ-vmlinux\", \"XZ\", \n",
    "              \"LZO-bzImage\", \"LZO-vmlinux\", \"LZO\", \"LZ4-bzImage\", \"LZ4-vmlinux\", \"LZ4\"]\n",
    "\n",
    "tri_state_values = ['y', 'n', 'm']\n",
    "\n",
    "ftuniques = []\n",
    "freq_ymn_features = []\n",
    "non_tristate_options = []\n",
    "\n",
    "for col in rawtuxdata:\n",
    "    ft = rawtuxdata[col]    \n",
    "    # eg always \"y\"\n",
    "    if len(ft.unique()) == 1:\n",
    "        ftuniques.append(col)\n",
    "    # only tri-state values (y, n, m) (possible TODO: handle numerical/string options)    \n",
    "    elif all(x in tri_state_values for x in ft.unique()):     #len(ft.unique()) == 3: \n",
    "        freq = ft.value_counts(normalize=True)\n",
    "        freqy = 0\n",
    "        freqn = 0\n",
    "        freqm = 0\n",
    "        if ('y' in freq.index):\n",
    "            freqy = freq['y']\n",
    "        if ('n' in freq.index):\n",
    "            freqn = freq['n']\n",
    "        if ('m' in freq.index):\n",
    "            freqm = freq['m']\n",
    "        freq_ymn_features.append((col, freqy, freqm, freqn))\n",
    "        # categorical variable\n",
    "        #if tuxdata[col].dtype == 'object':\n",
    "        #    try:\n",
    "        #        tuxdata[col] = tuxdata[col].astype('category')\n",
    "        #    except:\n",
    "        #        print('Column', ' ', col, ' cannot be converted to category.')\n",
    "    else:\n",
    "        if not (col in size_methods): \n",
    "            non_tristate_options.append(col)\n",
    "        \n",
    "\n",
    "### TODO: we want to keep all quantitative values!\n",
    "# non_tristate_options.remove('LZO') # ('vmlinux')\n",
    "\n",
    "# we want to keep measurements (that are not tristate ;)) \n",
    "# non_tristate_options = list(set(non_tristate_options) - set(size_methods))\n",
    "\n",
    "#### print options with unique values\n",
    "# options with only one value eg always \"y\"\n",
    "#i = 0\n",
    "#for ft in ftuniques:\n",
    "#    print(ft + \" (\" + str(i) + \")\")\n",
    "#    i = i + 1\n",
    "\n",
    "print(\"Original size (#configs/#options) of the dataset \" + str(rawtuxdata.shape))\n",
    "print (\"Number of options with only one value (eg always y): \" + str(pd.DataFrame(ftuniques).shape))\n",
    "\n",
    "# maybe we can drop options with only one unique value (no interest for machine learning)\n",
    "rawtuxdata.drop(columns=ftuniques,inplace=True)\n",
    "\n",
    "print (\"Non tri-state value options (eg string or integer or hybrid values): \" \n",
    "       + str(pd.DataFrame(non_tristate_options).shape) + \" \") \n",
    "#      + str(pd.DataFrame(non_tristate_options)))\n",
    "\n",
    "print (\"Predictor variables: \" + str(rawtuxdata.drop(columns=non_tristate_options).columns.size))\n",
    "# frequency of y, m, and n values \n",
    "#plt.figure()\n",
    "#pd.DataFrame(freq_ymn_features, columns=[\"feature\", \"freqy\", \"freqm\", \"freqn\"]).plot(kind='hist', alpha=0.8) #plot()\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtuxdata[rawtuxdata['vmlinux'] == 1168072][['cid', 'CC_OPTIMIZE_FOR_SIZE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtuxdata[rawtuxdata['vmlinux'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playing a bit with the data \n",
    "rawtuxdata.dtypes\n",
    "# 'DEBUG_INFOO' in list(pd.DataFrame(non_tristate_options)[0]) # \n",
    "# tuxdata['DEBUG_INFO'].unique()\n",
    "#tuxdata['OUTPUT_FORMAT'].dtypes\n",
    "#tuxdata['DEFAULT_HOSTNAME'].unique()\n",
    "\n",
    "#rawtuxdata[:5]\n",
    "rawtuxdata[:20]['vmlinux']\n",
    "#tuxdata[:5]['CONFIG_DEBUG_INFO']\n",
    "#tuxdata['ARCH_HAS_SG_CHAIN'].unique()\n",
    "#tuxdata['ARCH_HAS_SG_CHAIN'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtuxdata.shape, rawtuxdata[rawtuxdata['vmlinux'] != -1].shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "LEARN_COMPILATION_SUCCESS = False # costly in time and space \n",
    "compilation_status_column_name = 'compile_success'\n",
    "\n",
    "def encode_data_compilation(rawtuxdata):\n",
    "    lae = LabelEncoder()\n",
    "    # we save quantitative values we want (here vmlinux, TODO: generalize)\n",
    "    # the key idea is that the labelling encoder should not be applied to this kind of values (only to predictor variables!)\n",
    "    # vml = rawtuxdata['LZO'] # rawtuxdata['vmlinux'] \n",
    "    o_sizes = rawtuxdata[size_methods]\n",
    "\n",
    "    # we remove non tri state options, but TODO there are perhaps some interesting options (numerical or string) here\n",
    "    #tuxdata = rawtuxdata.drop(columns=non_tristate_options).drop(columns=['vmlinux']).apply(le.fit_transform)\n",
    "    tuxdata_for_compilation = rawtuxdata.drop(columns=non_tristate_options).drop(columns=size_methods).apply(lae.fit_transform)\n",
    "\n",
    "    #tuxdata['vmlinux'] = vml \n",
    "    tuxdata_for_compilation[size_methods] = o_sizes\n",
    "    tuxdata_for_compilation[compilation_status_column_name] = rawtuxdata['vmlinux'] != -1\n",
    "    return tuxdata_for_compilation\n",
    "\n",
    "def learn_compilation_success(tuxdata_for_compilation):\n",
    "    TESTING_SIZE=0.9 \n",
    "    X_train, X_test, y_train, y_test = train_test_split(tuxdata_for_compilation.drop(columns=size_methods).drop(columns=compilation_status_column_name), tuxdata_for_compilation[compilation_status_column_name], test_size=TESTING_SIZE, random_state=0)  \n",
    "    clf = GradientBoostingClassifier(n_estimators=100) #RandomForestRegressor(n_estimators=100) #   #GradientBoostingRegressor(n_estimators=100)  \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    importances = clf.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]    \n",
    "\n",
    "    TOP_FT_IMPORTANCE=20\n",
    "    print(\"Feature ranking: \" + \"top (\" + str(TOP_FT_IMPORTANCE) + \")\")\n",
    "    for f in range(TOP_FT_IMPORTANCE): # len(indices)\n",
    "        print(\"%d. feature %s %d (%f)\" % (f + 1, tuxdata_for_compilation.columns[indices[f]], indices[f], importances[indices[f]]))\n",
    "\n",
    "    acc = accuracy_score (y_test, y_pred)\n",
    "    prec = precision_score (y_test, y_pred)\n",
    "    reca = recall_score (y_test, y_pred)\n",
    "    f1 = f1_score (y_test, y_pred)\n",
    "    print(\"Accuracy score: %.2f\" % (acc))\n",
    "    print(\"Precision score: %.2f\" % (prec))\n",
    "    print(\"Recall score: %.2f\" % (reca))\n",
    "    print(\"F1 score: %.2f\" % (f1))\n",
    "\n",
    "if (LEARN_COMPILATION_SUCCESS):\n",
    "    tuxdata_for_compilation = encode_data_compilation(rawtuxdata)\n",
    "    tuxdata_for_compilation [compilation_status_column_name].describe()\n",
    "    learn_compilation_success(tuxdata_for_compilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove entries with same configurations\n",
    "print(str(len(rawtuxdata)) + \" before the removal of some entries (those with same configurations)\")\n",
    "# tuxdata.drop_duplicates(subset=tuxdata.columns.difference(['vmlinux']), inplace=True)\n",
    "#TODO: seems not working \n",
    "rawtuxdata.drop_duplicates(subset=rawtuxdata.columns.difference(size_methods), inplace=True)\n",
    "print(str(len(rawtuxdata)) + \" after the removal of some entries (those with same configurations)\")\n",
    "\n",
    "#n_failures = len(tuxdata[~np.isnan(tuxdata['vmlinux'])])\n",
    "n_failures = len(rawtuxdata[rawtuxdata['vmlinux'] == -1]) #len(tuxdata[np.isnan(tuxdata['vmlinux'])])\n",
    "print(str(n_failures) + \" failures out of \" + str(len(rawtuxdata)))\n",
    "\n",
    "#tuxdata = tuxdata[~np.isnan(tuxdata['vmlinux'])]\n",
    "rawtuxdata = rawtuxdata[rawtuxdata['vmlinux'] != -1] #tuxdata[~np.isnan(tuxdata['vmlinux'])]\n",
    "print(str(len(rawtuxdata)) + \" after the removal of configurations that do NOT compile\")\n",
    "\n",
    "\n",
    "\n",
    "#tuxdata[\"vmlinux\"]\n",
    "#tuxdata.where(tuxdata[\"vmlinux\"] == np.NaN)\n",
    "\n",
    "#tuxdata[tuxdata[\"vmlinux\"] != -1]\n",
    "#tuxdata\n",
    "#tuxdata[tuxdata['vmlinux'] != -1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"some configurations have X86_32 (coz we have tested/tried some options and there are in the database)\", rawtuxdata['X86_64'].describe())\n",
    "# we only keep X86_64 configurations\n",
    "rawtuxdata = rawtuxdata[rawtuxdata['X86_64'] == 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "pd.DataFrame(rawtuxdata['vmlinux']).plot.box()\n",
    "plt.show(block=False)\n",
    "\n",
    "plt.figure()\n",
    "pd.DataFrame(rawtuxdata['LZO']).plot.box()\n",
    "plt.show(block=False)\n",
    "\n",
    "plt.figure()\n",
    "pd.DataFrame(rawtuxdata['BZIP2']).plot.box()\n",
    "plt.show(block=False)\n",
    "\n",
    "\n",
    "rawtuxdata['vmlinux'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "def color_negative_positive(val, pcolor=\"green\", ncolor=\"red\"):\n",
    "    \"\"\"\n",
    "    Takes a scalar and returns a string with\n",
    "    the css property `'color: red'` for negative\n",
    "    strings, black otherwise.\n",
    "    \"\"\"\n",
    "    color = pcolor if val > 0 else ncolor \n",
    "    if val == 0:\n",
    "        color = 'black' \n",
    "    return 'color: %s' % color\n",
    "\n",
    "compress_methods = [\"GZIP\", \"BZIP2\", \"LZMA\", \"XZ\", \"LZO\", \"LZ4\"]\n",
    "def compareCompress(size_measure_of_interest): #\"\" # \"-vmlinux\" #\"-bzImage\" # prefix\n",
    "    rCompressDiff = pd.DataFrame(index=list(map(lambda c: c + \"o\", compress_methods)) , columns=compress_methods) \n",
    "    for compress_method in compress_methods:\n",
    "        for compress_method2 in compress_methods:\n",
    "            rCompressDiff.loc[compress_method + \"o\"][compress_method2] = (np.mean(rawtuxdata[compress_method + size_measure_of_interest] / rawtuxdata[compress_method2 + size_measure_of_interest]) * 100) - 100\n",
    "    return rCompressDiff\n",
    "\n",
    "#cmy = sns.light_palette(\"red\", as_cmap=True)\n",
    "compareCompress(\"\").style.set_caption('Difference (average in percentage) per compression methods').applymap(color_negative_positive)\n",
    "\n",
    "#(rawtuxdata[\"XZ-vmlinux\"] - rawtuxdata[\"BZIP2-vmlinux\"]).plot.box()\n",
    "# n_size_methods = len(size_methods)\n",
    "#corr_sizes = [[0 for x in range(n_size_methods)] for y in range(n_size_methods)]\n",
    "#i = 0\n",
    "#j = 0\n",
    "#for size_method in size_methods:\n",
    "#    csize = rawtuxdata[size_method]   \n",
    "#    for osize_method in size_methods:\n",
    "#        if size_method != osize_method:\n",
    "#            osize = rawtuxdata[osize_method]           \n",
    "#            pcorr = scipy.stats.pearsonr(csize, osize)[0]\n",
    "#            corr_sizes[i][j] = pcorr\n",
    "#        j = j + 1\n",
    "#    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compareCompress(\"-bzImage\").style.set_caption('Difference (average in percentage) per compression methods, bzImage').applymap(color_negative_positive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compareCompress(\"-vmlinux\").style.set_caption('Difference (average in percentage) per compression methods, vmlinux').applymap(color_negative_positive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "pd.DataFrame.corr(rawtuxdata[size_methods]).style.set_caption('Correlations between size measures').background_gradient(cmap=cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from category_encoders import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "#X = [['y', 1], ['n', 3], ['m', 2]]\n",
    "#enc.fit(X)\n",
    "#enc.transform(tuxdata)\n",
    "\n",
    "#enc = OrdinalEncoder().fit(tuxdata[:10])\n",
    "\n",
    "# transform the dataset\n",
    "#enc.transform(tuxdata[:10])\n",
    "\n",
    "# 1. INSTANTIATE\n",
    "# encode labels with value between 0 and n_classes-1.\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "# 2/3. FIT AND TRANSFORM\n",
    "# use df.apply() to apply le.fit_transform to all columns\n",
    "#print(non_tristate_options)\n",
    "\n",
    "# we save quantitative values we want (here vmlinux, TODO: generalize)\n",
    "# the key idea is that the labelling encoder should not be applied to this kind of values (only to predictor variables!)\n",
    "# vml = rawtuxdata['LZO'] # rawtuxdata['vmlinux'] \n",
    "vml = rawtuxdata[size_methods]\n",
    "\n",
    "# we remove non tri state options, but TODO there are perhaps some interesting options (numerical or string) here\n",
    "#tuxdata = rawtuxdata.drop(columns=non_tristate_options).drop(columns=['vmlinux']).apply(le.fit_transform)\n",
    "tuxdata = rawtuxdata.drop(columns=non_tristate_options).drop(columns=size_methods).apply(le.fit_transform)\n",
    "\n",
    "#tuxdata['vmlinux'] = vml \n",
    "tuxdata[size_methods] = vml\n",
    "# tuxdata['vmlinux'].astype('int64')\n",
    "\n",
    "# example: DEBUG_INFO is either y or n\n",
    "tuxdata['DEBUG_INFO'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (\"Warning, we only focus on configurations without DEBUG_INFO \")\n",
    "#tuxdata = tuxdata[tuxdata['DEBUG_INFO'] == le.transform(['n'])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuxdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuxdata.where(not np.isnan(tuxdata[\"vmlinux\"]))\n",
    "#tuxdata[\"vmlinux\"][16] == np.isnan\n",
    "#vml == -1 \n",
    "#tuxdata[\"vmlinux\"] == -1\n",
    "#tuxdata['vmlinux'].dtypes\n",
    "#vml.dtypes\n",
    "#tuxdata['vmlinux'].dtypes #.astype('int64')\n",
    "#TODO: remove configurations like this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuxdata.where(tuxdata[\"vmlinux\"] != -1).sort_values(by='vmlinux')[:5] # & \n",
    "print(tuxdata['UBSAN_SANITIZE_ALL'].value_counts(), tuxdata['COMPILE_TEST'].value_counts(), tuxdata['NOHIGHMEM'].value_counts(), tuxdata['OPTIMIZE_INLINING'].value_counts(), tuxdata['SLOB'].value_counts(), tuxdata['CC_OPTIMIZE_FOR_SIZE'].value_counts(), sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "TESTING_SIZE=0.9 \n",
    "\n",
    "# drop(columns=[\"date\", \"time\", \"vmlinux\", \"cid\"])\n",
    "# tuxdata.drop(columns=non_tristate_options)\n",
    "\n",
    "linearRegression=False\n",
    "size_of_interest = \"vmlinux\" # could be LZO, BZIP, etc. \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tuxdata.drop(columns=size_methods), tuxdata[size_of_interest], test_size=TESTING_SIZE, random_state=0)  \n",
    "# multi output\n",
    "#X_train, X_test, y_train, y_test = train_test_split(tuxdata.drop(columns=size_methods), tuxdata[size_methods], test_size=TESTING_SIZE, random_state=0)  \n",
    "\n",
    "# train_test_split(tuxdata.drop(columns=['vmlinux']), tuxdata['vmlinux'], test_size=TESTING_SIZE, random_state=0)  \n",
    "\n",
    "#clf = RandomForestRegressor(n_estimators=100) \n",
    "\n",
    "if linearRegression:\n",
    "    regr =  linear_model.Lasso() # svm.SVC(kernel='linear') # linear_model.Ridge(alpha=.1) #  # linear_model.Lasso() # linear_model.SGDRegressor() #LinearRegression() # SGDRegressor or linear_model.Lasso()\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred = regr.predict(X_test)\n",
    "else:\n",
    "    clf = GradientBoostingRegressor(n_estimators=100) # RandomForestRegressor(n_estimators=100) #   \n",
    "    # \n",
    "    #clf = Pipeline([\n",
    "    #  ('feature_selection', SelectFromModel(LassoCV(tol = 0.001))),\n",
    "    #  ('regression', GradientBoostingRegressor(n_estimators=100))\n",
    "    # ])\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    importances = clf.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]    \n",
    "\n",
    "    TOP_FT_IMPORTANCE=100\n",
    "    print(\"Feature ranking: \" + \"top (\" + str(TOP_FT_IMPORTANCE) + \")\")\n",
    "    for f in range(TOP_FT_IMPORTANCE): # len(indices)\n",
    "        print(\"%d. feature %s %d (%f)\" % (f + 1, tuxdata.columns[indices[f]], indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "#plt.figure()\n",
    "#plt.title(\"Feature importances for size of vmlinux\")\n",
    "#plt.bar(range(tuxdata.shape[1]), importances[indices], color=\"r\", align=\"center\")\n",
    "#plt.xticks(range(tuxdata.shape[1]), indices)\n",
    "#plt.xlim([-1, tuxdata.shape[1]])\n",
    "#plt.show()\n",
    "mae = mean_absolute_error (y_test, y_pred)# , multioutput='raw_values')\n",
    "mse = mean_squared_error (y_test, y_pred) #, multioutput='raw_values') \n",
    "r2 = r2_score (y_test, y_pred) #, multioutput='raw_values') \n",
    "\n",
    "ONE_MEGABYTE = 1048576\n",
    "\n",
    "print(\"Prediction score (MAE): %.2f\" % (mae / ONE_MEGABYTE))\n",
    "print(\"Prediction score (MSE): %.2f\" % (mse / ONE_MEGABYTE))\n",
    "print(\"Prediction score (R2): %.2f\" % (r2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "tuxdata_reduced = model.transform(tuxdata.drop(columns=size_methods))\n",
    "tuxdata_reduced.shape, tuxdata.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lass = SelectFromModel(LassoCV(tol = 0.001))\n",
    "#lass.fit(X_train, y_train)\n",
    "#tuxdata_reduced_lass = lass.transform(tuxdata.drop(columns=size_methods))\n",
    "#tuxdata_reduced_lass.shape, tuxdata.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_vals = ['y', 'n'] \n",
    "tri_state_values = ['y', 'n', 'm']\n",
    "all(x in tri_state_values for x in ft_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tux1 in tuxdata:\n",
    "#    ft1 = tuxdata[tux1]\n",
    "#    for tux2 in tuxdata:\n",
    "#        if (tux1 != tux2):\n",
    "#            if (ft1.all() == tuxdata[tux2].all()):\n",
    "#                print (\"feature \" + str(tux1) + \" always have the same values than \" + str(tux2))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provisoire = pd.read_csv(open('provisoire.csv', \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provisoire[['cid','CC_OPTIMIZE_FOR_SIZE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rawtuxdata.columns[6015] #Columns (1150,6015,6026,7676,7726)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
